{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de riesgo de una compañía aseguradora\n",
    "\n",
    "- Instituto Tecnológico y de Estudios Superiores de Monterrey\n",
    "\n",
    "| Alumno  | Matrícula |\n",
    "| :-----: |  :-----:  |\n",
    "| Verónica Victoria García De la Fuente | A00830383 |\n",
    "| Emily Rebeca Méndez Cruz              | A00830768 |\n",
    "| Daniel de Zamacona Madero             | A01570576 |\n",
    "| Eugenio Santiesteban Zolezzi          | A01720932 |\n",
    "| Juan Pablo Echeagaray González        | A00830646 |\n",
    "\n",
    "- Profesores:\n",
    "  - Dr. Fernando Elizalde Ramírez\n",
    "  - Dr. Jaime Eduardo Martínez Sánchez\n",
    "- Optimización estocástica\n",
    "- 10 de septiembre del 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.stats.gof import chisquare\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('text', usetex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27121, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha del Siniestro</th>\n",
       "      <th>Tipo de auto</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Monto del siniestro</th>\n",
       "      <th>Aplica cobertura</th>\n",
       "      <th>Deducible</th>\n",
       "      <th>Reclamo de no-Cobertura</th>\n",
       "      <th>Pérdida total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2020</td>\n",
       "      <td>Deportivo</td>\n",
       "      <td>2017</td>\n",
       "      <td>200000</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/05/2020</td>\n",
       "      <td>Austero</td>\n",
       "      <td>2016</td>\n",
       "      <td>100000</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/01/2020</td>\n",
       "      <td>compacto</td>\n",
       "      <td>2017</td>\n",
       "      <td>150000</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21/12/2020</td>\n",
       "      <td>Subcompacto</td>\n",
       "      <td>2017</td>\n",
       "      <td>70000</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/05/2020</td>\n",
       "      <td>Subcompacto</td>\n",
       "      <td>2019</td>\n",
       "      <td>90000</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fecha del Siniestro Tipo de auto  Modelo  Monto del siniestro  \\\n",
       "0          01/12/2020    Deportivo    2017               200000   \n",
       "1          12/05/2020      Austero    2016               100000   \n",
       "2          11/01/2020     compacto    2017               150000   \n",
       "3          21/12/2020  Subcompacto    2017                70000   \n",
       "4          30/05/2020  Subcompacto    2019                90000   \n",
       "\n",
       "  Aplica cobertura  Deducible Reclamo de no-Cobertura Pérdida total  \n",
       "0               Si        NaN                      Si            Si  \n",
       "1               Si        NaN                      Si            Si  \n",
       "2               Si        NaN                      Si            Si  \n",
       "3               Si        NaN                      Si            Si  \n",
       "4               Si        NaN                      Si            Si  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/insurance-data.csv', encoding='latin-1')\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una buena práctica con el manejo de datos es asegurarnos de que sean representados por un _tipo_ de dato acorde al valor que representa la variable, esto ayudará a realizar operaciones con ellos, así como minimizar el espacio en memoria que ocupan. Cambiaremos también el nombre de las columnas para que sea más sencillo el proceso de desarrollo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'Fecha del Siniestro': 'date',\n",
    "                'Tipo de auto': 'car_type',\n",
    "                'Modelo': 'model',\n",
    "                'Monto del siniestro': 'amount',\n",
    "                'Aplica cobertura': 'coverage', \n",
    "                'Deducible': 'deductible', \n",
    "                'Reclamo de no-Cobertura': 'no_claim',\n",
    "                'Pérdida total': 'total_loss'}\n",
    "\n",
    "df.rename(columns=column_names, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.car_type.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo continuaremos con la tarea de limpieza de datos, tratando valores nulos, convirtiendo variables del tipo booleanas a una representación adecuada, y cambiando el formato de la columna que describe el momento en el que ocurrió un siniestro. Estas transformaciones facilitarán el proceso de análisis y visualización de los mismos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_map = {'Deportivo': 0, \n",
    "        'Austero': 1, \n",
    "        'compacto': 2, \n",
    "        'Subcompacto': 3,\n",
    "        'Camioneta': 4,\n",
    "        'De Lujo': 5\n",
    "}\n",
    "df['car_type'] = df['car_type'].map(car_map)\n",
    "df['car_type'] = df['car_type'].fillna(99)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "# Codificando variables booleanas a 0 y 1\n",
    "df['coverage'] = df['coverage'].map({'Si': 1, 'No': 0})\n",
    "df['no_claim'] = df['no_claim'].map({'Si': 1, 'No': 0})\n",
    "df['total_loss'] = df['total_loss'].map({'Si': 1, 'No': 0})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un último paso de limpieza que garantiza que nuestro proyecto sea válido, es solamente considerar aquellos casos en los que si aplicó el seguro; este trabajo no analizará aquellos casos en los que el seguro de los clientes de la empresa no haya podido actuar por el motivo que sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df[df['coverage'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de parámetros\n",
    "\n",
    "La siguiente etapa del proyecto será analizar los montos pagados en cada siniestro así como la frecuencia con la que estos ocurren. Es de nuestro interés conocer las distribuciones tanto los respectivos parámetros que modelan estos fenómenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre el monto de los siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_use['amount'], height=6, aspect=8/6, kde=True)\n",
    "plt.xlabel('Monto del siniestro')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución del monto de los siniestros');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una primera visualización de los montos de los siniestros nos haría pensar que una distribución exponencial podría ser bien ajustada a nuestros datos muestrales. Empíricamente podemos observar un pico al comienzo de la gráfica, y un continuo descenso hacia frecuencias de 0 para los montos más elevados registrados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de hipótesis sobre la distribución del monto de los siniestros\n",
    "\n",
    "<!-- @article{lilliefors1969kolmogorov,\n",
    "  title={On the Kolmogorov-Smirnov test for the exponential distribution with mean unknown},\n",
    "  author={Lilliefors, Hubert W},\n",
    "  journal={Journal of the American Statistical Association},\n",
    "  volume={64},\n",
    "  number={325},\n",
    "  pages={387--389},\n",
    "  year={1969},\n",
    "  publisher={Taylor \\& Francis}\n",
    "} -->\n",
    "\n",
    "Realizaremos una prueba de hipótesis para ver si existe información estadística suficiente como para aseverar que el monto de los reclamos sigue una distribución exponencial $X \\sim \\text{Exp}(\\lambda = 32198.560688)$, realizaremos esta prueba con un nivel de significancia $\\alpha = 0.01$. Como método de prueba usaremos Lilliefors, propuesto en su artículo XXXX:\n",
    "\n",
    "$$\\begin{gather*}\n",
    "    H_o: X \\sim \\text{Exp}(\\lambda) \\\\\n",
    "    H_a: X \\not \\sim \\text{Exp}(\\lambda)\n",
    "\\end{gather*}$$\n",
    "\n",
    "> Lilliefors, H. W. (1969). On the Kolmogorov-Smirnov test for the exponential distribution with mean unknown. Journal of the American Statistical Association, 64(325), 387-389."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_val = lilliefors(df_use['amount'], dist='exp', pvalmethod='approx')\n",
    "print(f'Test Statistic: {stat}, p-value: {p_val}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `p-value` obtenido no es menor al nivel de significancia que hemos establecido para nuestra prueba, por lo que hemos fallado el rechazo de la hipótesis nula. De ahora en adelante supondremos que los montos de los siniestros siguen una distribución exponencial.\n",
    "$$\\begin{equation}\n",
    "    X \\sim \\text{Exp}(\\lambda)\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de hipótesis sobre la media del monto\n",
    "\n",
    "Sabiendo que la distribución exponencial modela esta variable aleatoria, queremos ahora saber el parámetro que mejor se ajuste a nuestros datos. Dado que el parámetro $\\lambda$ de la distribución exponencial es equivalente a la media de la población, supondremos que el parámetro puede ser aproximado por la media muestral de esta variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_amount = df_use['amount'].describe()['mean']\n",
    "print(f'Lambda = {mean_amount}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos ahora una prueba de hipótesis con una signifcancia $\\alpha = 0.05$ para la media de los montos de los siniestros:\n",
    "$$\\begin{gather*}\n",
    "    H_o: \\lambda = \\bar{\\lambda} \\\\\n",
    "    H_a: \\lambda \\neq \\bar{\\lambda}\n",
    "\\end{gather*}$$\n",
    "\n",
    "Como tenemos una muestra con más de 27,000 valores, podremos suponer que por el Teorema Central del Límite la media sigue una distribución normal; así que una prueba de hipótesis `t-student` bastará para comprobar nuestro supuesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_1samp(df_use['amount'], mean_amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `p-value` que hemos obtenido no es menor al nivel de significancia establecido, por lo que no podemos rechazar la hipótesis nula. Supondremos que la media muestral de nuestra base de datos es representativa de la media poblacional.\n",
    "\n",
    "Ahora podemos modelar la variable aleatoria de los montos como:\n",
    "$$\\begin{equation}\n",
    "    X \\sim \\text{Exp}(\\lambda = 30,771.375)\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervalo de confianza para la media de los siniestros\n",
    "\n",
    "Finalmente, es de nuestro interés conocer un intervalo de confianza para nuestra estimación; seguiremos la misma convención de usar un nivel de significancia del $0.05$, y aprovecharemos el Teorema Central del Límite aplicado a medias para calcular nuestro intervalo de confianza como:\n",
    "$$\\begin{equation}\n",
    "    CI = \\bar{x} \\pm z_{\\alpha} \\frac{s}{\\sqrt{n}}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "CI_amount = st.norm.interval(1 - alpha, loc=mean_amount, scale=st.sem(df_use['amount']))\n",
    "print(f'CI ({(1-alpha) * 100}%) = {CI_amount}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre el número de reclamos por día\n",
    "\n",
    "Ahora nos gustaría conocer qué proceso modela el número de reclamos por día. Sabemos de antemano que este es un proceso estocástico de conteo; así que una de las opciones de modelado más atractivas es la del proceso de Poisson. Primero observaremos la distribución de nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_per_day = df_use.groupby('date').count()['amount'].values\n",
    "sample_size = claims_per_day.shape[0]\n",
    "mean_claims_per_day = np.mean(claims_per_day)\n",
    "std_claims_per_day = np.std(claims_per_day)\n",
    "var = np.var(claims_per_day)\n",
    "print(f'''Estadísticos:\n",
    "Sample size: {sample_size}\n",
    "Mean claims per day: {mean_claims_per_day}\n",
    "Standard deviation: {std_claims_per_day}\n",
    "Variance: {var}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.barplot(x=np.arange(0, sample_size), y=claims_per_day, color='red', saturation=0.5)\n",
    "ax.set_title('Cantidad de siniestros por día')\n",
    "ax.set_xlabel('Día')\n",
    "ax.set_ylabel('Cantidad de siniestros')\n",
    "new_ticks = [i.get_text() for i in ax.get_xticklabels()]\n",
    "plt.xticks(range(0, len(new_ticks), 20), new_ticks[::20])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de hipótesis sobre la distribución del número de reclamos por día\n",
    "\n",
    "Para demostrar que este proceso es Poisson homogéneo, aprovecharemos que un proceso de Poisson homogéneo sigue una distribución Poisson. Realizaremos una prueba de bondad de ajuste `chi-square` para determinar si es que esa distribución se ajusta a nuestro proceso estocástico. Usaremos un nivel de significancia del 0.05:\n",
    "\n",
    "$$\\begin{gather*}\n",
    "    H_o: X \\sim \\text{Poi}(\\lambda t) \\\\\n",
    "    H_a: X \\not \\sim \\text{Poi}(\\lambda t)\n",
    "\\end{gather*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.random.poisson(mean_claims_per_day, sample_size)\n",
    "\n",
    "chisquare(claims_per_day, test_sample, value=0.15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `p-value` que hemos calculado no es menor que el nivel de significancia establecido, por lo que modelaremos este proceso estocástico como un proceso de Poisson homogéneo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de hipótesis sobre la media del número de reclamos por día\n",
    "\n",
    "Realizamos una prueba de hipótesis sobre la media del número de reclamos, el parámetro que deseamos estimar es también el parámetro que necesita un proceso de Poisson. De nuevo aprovecharemos el Teorema Central del Límite para suponer que esta media sigue una distribución normal, hay que recordar que para este dato tenemos concretamente 365 observaciones. Usaremos un nivel de significancia del 0.05:\n",
    "$$\\begin{gather*}\n",
    "    H_o: \\lambda = \\bar{\\lambda} \\\\\n",
    "    H_a: \\lambda \\neq \\bar{\\lambda}\n",
    "\\end{gather*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervalo de confianza para la media del número de reclamos por día\n",
    "\n",
    "Aquí también es de nuestro interés conocer un intervalo de confianza para nuestra estimación; seguiremos la misma convención de usar un nivel de significancia del $0.05$, y aprovecharemos el Teorema Central del Límite aplicado a medias para calcular nuestro intervalo de confianza como:\n",
    "$$\\begin{equation}\n",
    "    CI = \\bar{x} \\pm z_{\\alpha} \\frac{s}{\\sqrt{n}}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "CI_claims = st.norm.interval(1 - alpha, loc=mean_claims_per_day, scale=st.sem(claims_per_day))\n",
    "print(f'CI ({(1-alpha) * 100}%): {CI_claims}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencia entre el monto de reclamos y el número de reclamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una muestra aleatoria de los reclamos\n",
    "amounts_sample = df_use['amount'].sample(len(claims_per_day), replace=True, random_state=42)\n",
    "pearsonr(claims_per_day, amounts_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_amount = df_use['amount'].describe()['mean']\n",
    "mean_claims = df_use.groupby('date').count()['amount'].mean()\n",
    "print(f'Lambda = {mean_amount}')\n",
    "print(f'Mean claims per day = {mean_claims}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total del reclamo por instante $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_claims(claim_rate: float, mean_amount: float) -> float:\n",
    "    number_claims = np.random.poisson(claim_rate)\n",
    "    amount = np.random.exponential(mean_amount, number_claims)\n",
    "    return np.sum(amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectando ruinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ruin(T: int, claim_rate: float, mean_amount: float, initial_equity: float, c: float) -> tuple:\n",
    "    U = np.array([])\n",
    "    # S1 = generate_claims(claim_rate, mean_amount)\n",
    "    P = c\n",
    "    U = np.append(U, initial_equity)\n",
    "\n",
    "    R = 0\n",
    "    for i in range(1, T):\n",
    "        S = generate_claims(claim_rate, mean_amount)\n",
    "        new_U = U[i-1] + P - S\n",
    "        U = np.append(U, new_U)\n",
    "        if U[i] < 0:\n",
    "            R += 1\n",
    "            break\n",
    "\n",
    "    return R, U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Monte Carlo Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruin_prob(n_sim: int, T: int, claim_rate: float, mean_amount: float, initial_equity: float, c: float, alpha: float) -> tuple:\n",
    "    ruins = np.array([])\n",
    "    paths = []\n",
    "\n",
    "    for _ in range(int(n_sim)):\n",
    "        R, U = test_ruin(T, claim_rate, mean_amount, initial_equity, c)\n",
    "        ruins = np.append(ruins, R)\n",
    "        paths.append(U)\n",
    "    \n",
    "    CI = proportion_confint(sum(ruins), n_sim, alpha=alpha, method='normal')\n",
    "\n",
    "    return np.mean(ruins), paths, CI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad de ruina analítica. Fórmula de Pollaczcek-Khinchin\n",
    "\n",
    "$$\\begin{gather*}\n",
    "    u := \\text{Capital inicial} \\\\\n",
    "    \\theta := \\text{Factor de recargo} \\\\\n",
    "    \\alpha := \\frac{1}{\\lambda_Z} \\\\\n",
    "    \\psi(u) = \\frac{1}{1 + \\theta} \\cdot \\exp \\left(u \\frac{\\alpha \\theta}{1 + \\theta} \\right)\n",
    "\\end{gather*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pollaczek_khinchin(theta: float, u: float, lam_z: float) -> float:\n",
    "    alpha = 1 / lam_z\n",
    "    prob = (1 / (1 + theta)) * np.exp(- alpha * u * (theta / (1 + theta)))\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U0 = 1000000\n",
    "alpha = 0.01\n",
    "# Factor de recargo\n",
    "theta = 0.05\n",
    "c = (1 + theta) * mean_claims * mean_amount\n",
    "print(f'c = {c}')\n",
    "T = 120\n",
    "N_SIM = 100\n",
    "ruins, paths, CI = ruin_prob(N_SIM, T, mean_claims, mean_amount, U0, c, alpha)\n",
    "print(f'P(Ruins): {ruins}')\n",
    "print(f'CI ({(1-alpha) * 100}%): {CI}, Error = {0.5 * (CI[1] - CI[0])}')\n",
    "p_analytic = pollaczek_khinchin(theta, U0, mean_amount)\n",
    "print(f'P(Ruins) (analytic): {p_analytic}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(f'Simulación del proceso de riesgo \\n P(Ruina) = {ruins} \\n CI = ({CI[0]:.4f}, {CI[1]:.4f})')\n",
    "plt.xlabel('Día')\n",
    "plt.ylabel('Capital')\n",
    "for path in paths:\n",
    "    plt.plot(path)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades analíticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variación del factor de recargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_theta():\n",
    "    # Variando theta\n",
    "    pos_theta = np.linspace(0, 1, 100)\n",
    "    prob = np.array([])\n",
    "    for theta in pos_theta:\n",
    "        prob = np.append(prob, pollaczek_khinchin(theta, U0, mean_amount))\n",
    "\n",
    "    # Visualización de resultados\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(r'Probabilidad de ruina en función de $\\theta$. $U_0 = 1000000$')\n",
    "    plt.xlabel(r'$\\theta$')\n",
    "    plt.ylabel('Probabilidad de ruina')\n",
    "    plt.plot(pos_theta, prob, label='Pollaczeck-Khinchin')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_theta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variación del capital inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_u0():\n",
    "    U = np.linspace(0, 1e7, 100)\n",
    "    prob = np.array([])\n",
    "    for u in U:\n",
    "        prob = np.append(prob, pollaczek_khinchin(theta, u, mean_amount))\n",
    "\n",
    "    # Visualización de resultados\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(r'Probabilidad de ruina en función de $U_0$, $\\theta = 0.05$')\n",
    "    plt.xlabel(r'$U_0$')\n",
    "    plt.ylabel('Probabilidad de ruina')\n",
    "    plt.plot(U, prob, label='Pollaczeck-Khinchin')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_u0()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4636cee7ff2c0f2b78d4f95d17cbcb397898fa210100f5db34fda65c633da2ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
